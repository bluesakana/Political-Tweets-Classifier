{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4a6495-1dc8-4502-9437-11e0cdb18ca2",
   "metadata": {},
   "source": [
    "<img src=\"../images/GA-logo.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Web APIs and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0103410-7bad-4908-8fd5-7649c6271cb7",
   "metadata": {},
   "source": [
    "**Primary Objectives:**\n",
    "\n",
    "1. Scrape tweets from two Twitter accounts\n",
    "2. Use NLP to train a classifier to predict the account a given tweet comes from (i.e. binary classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "26d4e53c-2e32-4224-8b48-1de14c61132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import dill\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# remb to remove all the models, since this is only preproc feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e47688-03a5-4c58-be7d-e365ce0d1679",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## Data Import and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b56d9bad-f682-4ddd-92e1-e2dffd06570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the cleaned data files\n",
    "tweets = pd.read_csv('../datasets/tweets_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "dd651dde-616e-4155-9de0-b15268b8a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test datasets\n",
    "X = tweets[['cleanedContent', 'content_length', 'hashtags', 'sentiment_score',\n",
    "            'num_links_TextLink', 'num_media_Video', 'num_media_Photo', 'num_media_Gif',\n",
    "            'likeCount', 'quoteCount', 'part_of_convo']]\n",
    "y = tweets['account']\n",
    "# convert y into boolean, where pap=1 and wp=0\n",
    "y = pd.Series([1 if row == 'pap' else 0 for row in y], name=y.name)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e179f-551c-4412-bf0e-23e02936f375",
   "metadata": {},
   "source": [
    "----\n",
    "## Feature Engineering\n",
    "\n",
    "Taking into account the results from the EDA, we will engineer the features as follows:\n",
    "| Feature | Input Variables | Pre-Processing | Output Variables |\n",
    "|--------|--------|--------|--------|\n",
    "| Messaging | `cleanedContent` | Vectorise with TFIDF | `content_vec` |\n",
    "|  | `content_length` | No further processing | `content_length` |\n",
    "|  | `hashtags` | Vectorise with TFIDF | `hashtags_vec` |\n",
    "| Tone | `sentiment_score` | No further processing | `sentiment_score` |\n",
    "| Content Type | `num_links_TextLink`, `num_media_Video`, `num_media_Photo`, `num_media_Gif` | No further processing | `num_links_TextLink`, `num_media_Video`, `num_media_Photo`, `num_media_Gif` |\n",
    "| Level of Engagement | `likeCount`, `quoteCount`, `part_of_convo` | No further processing | `likeCount`, `quoteCount`, `part_of_convo` |\n",
    "\n",
    "MAYBE REMOVE OUTPUT VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52cbb9-d44a-4e2f-a6ca-783848c97c4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Messaging: vectorise `cleanedContent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1c37d84d-790a-444d-a1ee-e440a18073e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_with_blank(df):\n",
    "    \n",
    "    return df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9c7d7a6c-0f5f-4ede-8dd9-06908e923bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_column(df):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_col = []\n",
    "\n",
    "    for text in df:\n",
    "        tokens = word_tokenize(text)\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        lemm_col.append(' '.join(lemmatized_tokens))\n",
    "\n",
    "    return pd.Series(lemm_col, name=df.name)\n",
    "    #else:\n",
    "    #    return ''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d60b8-3239-4c0c-a568-63daba6c5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in tweets['cleanedContent']:\n",
    "    print(type(content))\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "71da0be2-4e2f-4140-8be5-0ffde6e4d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "tvec_content_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('filler', FunctionTransformer(fill_na_with_blank, feature_names_out='one-to-one')),\n",
    "        ('lemmatizer', FunctionTransformer(lambda x: lemmatize_column(x), feature_names_out='one-to-one')),\n",
    "        ('tvec_content', TfidfVectorizer())\n",
    "        #('denser', FunctionTransformer(lambda x: x.todense(), feature_names_out='one-to-one'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b6a4f-4b00-4740-812f-08fdc67783ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Messaging: vectorise `hashtags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d3928bf-b06e-44dd-bb50-b7dda177e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to vectorise and create dense matrix\n",
    "def convert_list_to_string(col):\n",
    "    \n",
    "    #col = col.fillna([])\n",
    "    \n",
    "    #return col.apply(lambda x: ' '.join(x))\n",
    "    #return col.apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "    return col.apply(lambda x: ' '.join(ast.literal_eval(x)) if isinstance(x, str) else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e2ad58d5-c4ad-46e0-bb66-6019b5e429ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline for vectorising hashtags\n",
    "# hashtags is a column in the dataframe with a list of strings for each row\n",
    "tvec_hashtag_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('filler', FunctionTransformer(fill_na_with_blank, feature_names_out='one-to-one')),\n",
    "        # join the list of words into a single string for each row\n",
    "        #('joiner', FunctionTransformer(lambda x: ' '.join(x) if isinstance(x, list) else '', feature_names_out='one-to-one')),\n",
    "        #('joiner', FunctionTransformer(convert_list_to_string, feature_names_out='one-to-one')),\n",
    "        # vectorise\n",
    "        ('tvec_hashtag', TfidfVectorizer()),\n",
    "        # convert to dense matrix\n",
    "        #('denser', FunctionTransformer(lambda x: x.todense(), feature_names_out='one-to-one'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084b9c5-e136-45bf-9486-29a181bb89d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tone: `sentiment_scores`\n",
    "\n",
    "We realise that `sentiment_scores` ranges from -1.0 to 1.0 and this will raise an error in Multinomial Naive Bayes classifier which only takes in positive values. As such, we need to transform `sentiment_scores` into variables - one for positive sentiment and one for negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "3f98cfaa-f66e-410b-9625-f628fcc4187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to transform sentiments_scores into positive and negative scores\n",
    "def transform_scores(df):\n",
    "    \n",
    "    df_trans = df.apply(lambda x: pd.Series([max(x,0), max(-x,0)]))\n",
    "    df_trans.columns = [df.name+'_pos', df.name+'_neg']\n",
    "    \n",
    "    return df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3675e-e5c4-4326-ba7c-e21c35ab07ed",
   "metadata": {},
   "source": [
    "### Pre-processor for all predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "dafb5eaa-75af-4d2f-b254-d2ac9c118c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all the preprocessing steps together in one pipeline for Multinomial Naive Bayes classifier which cannot take in negative values\n",
    "preprocessor_NB = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('sent_transformer', FunctionTransformer(transform_scores, feature_names_out='one-to_one'), 'sentiment_score'),\n",
    "        ('content_transformer', tvec_content_pipe, 'cleanedContent'),\n",
    "        ('hashtag_transformer', tvec_hashtag_pipe, 'hashtags')\n",
    "    ],\n",
    "    remainder='passthrough', verbose_feature_names_out=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "c9790f98-3882-46ab-8fe2-ddcd14412b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all the preprocessing steps together in one pipeline for other classifiers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('content_transformer', tvec_content_pipe, 'cleanedContent'),\n",
    "        ('hashtag_transformer', tvec_hashtag_pipe, 'hashtags')\n",
    "    ],\n",
    "    remainder='passthrough', verbose_feature_names_out=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c692e6-0f3c-4523-80ea-0a97411ab255",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Model fitting and evaluation\n",
    "\n",
    "For model evaluation, there are many metrics that can be used. For this problem statement, we will use F1 score to provide a balance between precision and recall. This is because:\n",
    "1. The dataset is quite balanced between the 2 Twitter accounts\n",
    "2. Classifying the tweet wrongly either way is equally detrimental\n",
    "\n",
    "Hence, we will not prioritise precision or recall but aim to get the best F1 score instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc95030-0f34-4e40-8885-641d210b414b",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "The baseline model takes a mean strategy. We check the F1 score for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "b7c48fd4-1553-46e1-9d36-6858b98c20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_test.value_counts(normalize=True).sort_values(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "15b2f9db-1f51-4fc5-b7cf-340821fa3490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for baseline model is 0.674.\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 Score for baseline model is {f1_score(y_test, y_pred*np.ones(y_test.shape)):.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd947d-f361-4194-ad24-5b0e812cd4ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model A: Naive Bayes\n",
    "\n",
    "We test out a Naive Bayes model and check its F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "572d6e3b-baaf-4c22-abb8-bc21cf5ec71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pipeline for model A\n",
    "model_NB = Pipeline(\n",
    "    steps=[\n",
    "        ('preproc', preprocessor_NB),\n",
    "        ('model', MultinomialNB())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "23f52916-7813-474c-a6bf-f33a00f9bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters for tuning\n",
    "model_NB_params = {\n",
    "    #'preproc__content_transformer__tvec_content__max_features': [100, 500, 1000, 2000, 3000, 4000, 5000, 6000],\n",
    "    'preproc__content_transformer__tvec_content__max_df': uniform(0,1),\n",
    "    'preproc__content_transformer__tvec_content__stop_words': [None, 'english'],\n",
    "    'preproc__content_transformer__tvec_content__ngram_range': [(1,1), (1,3), (2,3)],\n",
    "    'preproc__hashtag_transformer__tvec_hashtag__max_df': uniform(0,1),\n",
    "    'preproc__hashtag_transformer__tvec_hashtag__stop_words': [None, 'english'],\n",
    "    #'preproc__hashtag_transformer__tvec_hashtag__ngram_range': [(1,1)],\n",
    "    'model__alpha': uniform(0,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "2bb99501-22af-4771-894c-b482f86310ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct RandomizedSearchCV object to tune hyperparameters with F1 score as objective\n",
    "model_NB_randsearch = RandomizedSearchCV(\n",
    "    model_NB, model_NB_params, n_iter=20, cv=5, scoring='f1',\n",
    "    random_state=200, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8600ac-a40a-4406-9cb4-991c2e10e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit model and tune hyperparamters\n",
    "model_NB_randsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "f6815143-166e-4787-8ffb-5cac04f9103a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomizedSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [523], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# look at metrics\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_NB_train_score \u001b[38;5;241m=\u001b[39m f1_score(y_train, \u001b[43mmodel_NB_randsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m model_NB_cv_score \u001b[38;5;241m=\u001b[39m model_NB_randsearch\u001b[38;5;241m.\u001b[39mbest_score_\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain F1 Score: \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_NB_train_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dsi-sg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:499\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03m        the best found parameters.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dsi-sg\\lib\\site-packages\\sklearn\\utils\\validation.py:1345\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1341\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1342\u001b[0m     ]\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomizedSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# look at metrics\n",
    "model_NB_train_score = f1_score(y_train, model_NB_randsearch.predict(X_train))\n",
    "model_NB_cv_score = model_NB_randsearch.best_score_\n",
    "\n",
    "print(f'Train F1 Score: \\t{model_NB_train_score:.3f}')\n",
    "print(f'5-Fold CV F1 Score: \\t{model_NB_cv_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c08fd-9aee-4fa0-bcb5-0db5f5092802",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot = ConfusionMatrixDisplay(confusion_matrix(y_train, model_NB_randsearch.predict(X_train)), display_labels=['pap', 'wp'])\n",
    "\n",
    "cm_plot.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48657130-a635-4032-b6b8-2c8f54714013",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model A: Naive Bayes\n",
    "\n",
    "We test out a Naive Bayes model and check its F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193dcf60-7a0b-48b7-934a-bacc1c64d4df",
   "metadata": {},
   "source": [
    "## Later fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d412d9-ddec-492a-a9c3-5a28b07ce854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with tf-idf vectorizer and multinomial naive bayes\n",
    "\n",
    "pipe_tvec = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1c5b4-e470-454b-8220-046af6cc2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# No stop words and english stop words\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_tvec_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c6e1e-facf-4820-b481-a7c663238c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_tvec = GridSearchCV(pipe_tvec, # what object are we optimizing?\n",
    "                        param_grid = pipe_tvec_params, # what parameters values are we searching?\n",
    "                        cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b582857-8b34-4f99-bc62-7a12b73199b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tvec',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acce...\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('nb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'tvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'tvec__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs_tvec.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi-sg]",
   "language": "python",
   "name": "conda-env-dsi-sg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
